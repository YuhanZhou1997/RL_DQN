# RL_DQN

#由于使用回顾型数据，agent无法与环境进行直接交互
#因此直接存储完所有的one-step-transition [s,a,s',r]进行训练
